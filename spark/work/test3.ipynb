{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_data = pd.read_csv(\"./raw_data/sanfrancisco.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_columns = list(sf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_columns = ['snow_1h', 'snow_24h', 'rain_24h', 'rain_1h', 'snow_3h', 'rain_today', 'snow_today', 'weather_icon', 'weather_id', 'sea_level', 'grnd_level', 'lat', 'lon', 'city_id', 'city_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_columns = columns = list(set(raw_columns) - set(unused_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38415 entries, 0 to 38414\n",
      "Data columns (total 28 columns):\n",
      "dt                     38415 non-null int64\n",
      "dt_iso                 38415 non-null object\n",
      "city_id                38415 non-null int64\n",
      "city_name              0 non-null float64\n",
      "lat                    0 non-null float64\n",
      "lon                    0 non-null float64\n",
      "temp                   38415 non-null float64\n",
      "temp_min               38415 non-null float64\n",
      "temp_max               38415 non-null float64\n",
      "pressure               38415 non-null int64\n",
      "sea_level              0 non-null float64\n",
      "grnd_level             0 non-null float64\n",
      "humidity               38415 non-null int64\n",
      "wind_speed             38415 non-null int64\n",
      "wind_deg               38415 non-null int64\n",
      "rain_1h                1866 non-null float64\n",
      "rain_3h                1355 non-null float64\n",
      "rain_24h               97 non-null float64\n",
      "rain_today             137 non-null float64\n",
      "snow_1h                3 non-null float64\n",
      "snow_3h                0 non-null float64\n",
      "snow_24h               0 non-null float64\n",
      "snow_today             0 non-null float64\n",
      "clouds_all             38415 non-null int64\n",
      "weather_id             38415 non-null int64\n",
      "weather_main           38415 non-null object\n",
      "weather_description    38415 non-null object\n",
      "weather_icon           38415 non-null object\n",
      "dtypes: float64(16), int64(8), object(4)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "sf_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(raw_data, used_columns):\n",
    "    data = raw_data.loc[:, used_columns] \n",
    "    print(\"fill_na\")\n",
    "    data['rain_3h'] = data['rain_3h'].fillna(0)\n",
    "    print(\"drop_duplicates\")\n",
    "    data.drop_duplicates('dt', inplace=True)\n",
    "    print(\"add_new_dada\")\n",
    "    data = add_new_data(data)\n",
    "    \n",
    "    data = data.apply(transform_datetime, axis=1)\n",
    "    \n",
    "    unused_columns  = ['dt_iso', 'weather_main', 'weather_description', 'dt_datetime']\n",
    "    \n",
    "    data = data.drop(unused_columns, axis=1)\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "def add_new_data(data):\n",
    "    data['dt_datetime'] =  pd.to_datetime(data['dt_iso'], format='%Y-%m-%d %H:%M:%S +%f %Z')\n",
    "    weather_description_columns = list(set(data['weather_description']))\n",
    "    weather_main_columns = list(set(data['weather_main']))\n",
    "    data = transform_categorical_data(data, weather_description_columns,weather_main_columns)\n",
    "\n",
    "    return data\n",
    "\n",
    "def transform_categorical_data(data, weather_description_columns, weather_main_columns):\n",
    "    for column in weather_description_columns:\n",
    "        data[column] = data['weather_description'] == column\n",
    "        data[column] = data[column].astype(int)\n",
    "        \n",
    "    for column in weather_main_columns:\n",
    "        data[column] = data['weather_main'] == column\n",
    "        data[column] = data[column].astype(int)\n",
    "    return data\n",
    "    \n",
    "def transform_datetime(current_data):\n",
    "    for month in range(1, 12):\n",
    "        current_data['month_{}'.format(month)] = 1 if current_data['dt_datetime'].month == month else 0\n",
    "\n",
    "    current_data['year'] =  current_data['dt_datetime'].year\n",
    "    current_data['dayofweek'] = current_data['dt_datetime'].dayofweek\n",
    "    current_data['dayofyear'] = current_data['dt_datetime'].dayofyear\n",
    "    current_data['hourofday'] = current_data['dt_datetime'].hour\n",
    "    return current_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_na\n",
      "drop_duplicates\n",
      "add_new_dada\n"
     ]
    }
   ],
   "source": [
    "sf_data2 = cleanup(sf_data, used_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target_data(data):\n",
    "    data['target_temp'] = data['temp'][1:].append(pd.Series([np.nan]) , ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_data3 = add_target_data(sf_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_previous_datum(raw_data):\n",
    "#     data = raw_data.copy()\n",
    "#     diff_columns = list(set(raw_data.columns) - set(['dt', 'dt_iso', 'dt_datetime']))\n",
    "#     maximum_prev = 2 *  24\n",
    "#     data = data.apply(add_previous_data, args=(diff_columns, data, maximum_prev), axis=1)\n",
    "#     return data\n",
    "\n",
    "# def add_previous_data(current_data,  diff_columns, raw_data, maximum_prev):\n",
    "#     index = current_data.name\n",
    "#     print(index)\n",
    "#     if index == 0:\n",
    "#         return current_data\n",
    "#     prev_right = index - 1\n",
    "#     prev_left = index - maximum_prev if index - maximum_prev > 0 else 0\n",
    "       \n",
    "#     while prev_left <= prev_right:\n",
    "#         current_data = add_diff_data(current_data, raw_data.iloc[prev_left], maximum_prev, diff_columns)\n",
    "#         prev_left += 1\n",
    "#     return current_data\n",
    "\n",
    "# def add_diff_data(current_data, prev_data, maximum_prev, diff_columns):\n",
    "#     diff = int(pd.Timedelta(current_data['dt_datetime'] - prev_data['dt_datetime']).seconds/ 3600)\n",
    "#     if diff > 0 and diff < maximum_prev:\n",
    "#         for diff_column in diff_columns:\n",
    "#             column_name = '{}_{}_ago'.format(diff_column, diff)\n",
    "#             current_data[column_name] = prev_data[diff_column]\n",
    "#     return current_data\n",
    "\n",
    "# # add new data by merging np array and adding dummy data \n",
    "# #[NALL, NALL, data1, data2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_diff_data(raw_data):\n",
    "    data = raw_data.copy()\n",
    "    diff_columns = list(set(raw_data.columns) - set(['dt', 'dt_iso', 'dt_datetime', 'target_temp', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12', 'year', 'dayofyear', 'dayofweek', 'hourofday']))\n",
    "    maximum_prev = 2 *  24\n",
    "    for i in [1,2,3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48]:\n",
    "        for column in diff_columns:\n",
    "            data['{}_{}_ago'.format(column, i)] = pd.Series(np.repeat(np.nan, i)).append(data[column][:-i] , ignore_index=True)\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_data4 = add_diff_data(sf_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        289.13\n",
       "1        290.73\n",
       "2        293.02\n",
       "3        296.18\n",
       "4        299.66\n",
       "5        300.03\n",
       "6        301.07\n",
       "7        302.29\n",
       "8        304.70\n",
       "9        304.86\n",
       "10       304.08\n",
       "11       302.69\n",
       "12       300.52\n",
       "13       298.56\n",
       "14       297.94\n",
       "15       296.95\n",
       "16       294.14\n",
       "17       293.46\n",
       "18       293.32\n",
       "19       292.39\n",
       "20       291.96\n",
       "21       291.52\n",
       "22       290.75\n",
       "23       290.26\n",
       "24       297.49\n",
       "25       299.48\n",
       "26       301.24\n",
       "27       302.04\n",
       "28       303.25\n",
       "29       302.50\n",
       "          ...  \n",
       "33412    285.81\n",
       "33413    287.51\n",
       "33414    288.89\n",
       "33415    290.30\n",
       "33416    290.57\n",
       "33417    289.16\n",
       "33418    286.82\n",
       "33419    285.23\n",
       "33420    283.67\n",
       "33421    282.17\n",
       "33422    281.00\n",
       "33423    280.16\n",
       "33424    279.89\n",
       "33425    279.64\n",
       "33426    278.60\n",
       "33427    278.16\n",
       "33428    277.70\n",
       "33429    277.16\n",
       "33430    276.52\n",
       "33431    276.25\n",
       "33432    276.50\n",
       "33433    277.16\n",
       "33434    281.23\n",
       "33435    283.96\n",
       "33436    286.48\n",
       "33437    287.98\n",
       "33438    289.79\n",
       "33439    290.53\n",
       "33440    290.15\n",
       "33441       NaN\n",
       "Name: target_temp, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_data4['target_temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
